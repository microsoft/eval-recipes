name: product_review_finder
task_info:
  difficulty: medium
  non_deterministic_evals: true
  categories:
    - cli_tool
    - research
    - web_scraping
evaluation_configs:
  - type: score
    test_script: test.py
    test_command: uv run --no-project /project/test.py
dockerfile_portion: ""
instructions: |
  I need a CLI tool that finds professional product reviews from reputable sources. Put all the code under scenarios/product_review_finder.

  The tool should take a product name as input. Add a --category flag (optional) to help narrow down the search - like "laptop" or "smartphone" or "headphones".

  Here's how it should work:

  First, use ddgs (Dux Distributed Global Search) to find reviews from reputable tech sites, consumer reports, and trusted review publications. Analyze the search results and extract detailed content from the best sources.

  From there, have a writer component that creates a first draft of the markdown report including overall consensus, key strengths/weaknesses, ratings, quotes, citations with URLs and dates, and a final recommendation.

  After the initial draft, pass it through these reviewers:

  1. Pass the draft and the source reviews to an accuracy-reviewer to verify all claims are properly cited and nothing is misrepresented or fabricated - if issues found, give feedback and send back to the writer for fixes, then back to accuracy-reviewer.

  2. Once accuracy passes, send the draft to a completeness-reviewer to check that all required sections are present (consensus, strengths, weaknesses, ratings, quotes, citations, recommendation) and comprehensive enough - if issues, feedback to writer and back through accuracy-reviewer again.

  3. After completeness passes, send to a synthesis-reviewer to verify the report provides coherent analysis across sources and actionable recommendations, not just listing facts - if issues, feedback to writer and back through the other reviewers.

  Once all reviewers pass, write the draft to a file and give me the chance to add [bracket-enclosed-feedback] to the report. Then take my feedback and pass it back to the writer along with the original sources, go through the writer revision, and then back through all three reviewers again with my feedback included in their context.

  Save the final output to a timestamped markdown file named after the product.

  Include a README with usage examples.
timeout: 4500
